{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NrjX6NdS1tkd",
        "outputId": "8ca95dad-4ff5-4c13-8759-d4bb80ec9634"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================\n",
            "### A1, A2, A3: Regression Analysis Results ###\n",
            "==================================================\n",
            "\n",
            "--- Metrics for SIMPLE feature model (using 'Cz..__alpha') ---\n",
            "Training Set Metrics:\n",
            "  MSE: 0.0000\n",
            "  RMSE: 0.0000\n",
            "  MAPE (%): 118.2902\n",
            "  R2 Score: 0.7343\n",
            "\n",
            "Test Set Metrics:\n",
            "  MSE: 0.0000\n",
            "  RMSE: 0.0000\n",
            "  MAPE (%): 116.2607\n",
            "  R2 Score: 0.7262\n",
            "\n",
            "\n",
            "--- Metrics for MULTIPLE feature model (all attributes) ---\n",
            "Training Set Metrics:\n",
            "  MSE: 0.0000\n",
            "  RMSE: 0.0000\n",
            "  MAPE (%): 76.6149\n",
            "  R2 Score: 0.9090\n",
            "\n",
            "Test Set Metrics:\n",
            "  MSE: 0.0000\n",
            "  RMSE: 0.0000\n",
            "  MAPE (%): 75.2462\n",
            "  R2 Score: 0.9274\n",
            "\n",
            "==================================================\n",
            "### A4, A5, A6, A7: Clustering Analysis Results ###\n",
            "==================================================\n",
            "\n",
            "--- Clustering Evaluation Metrics for k=2 (A5) ---\n",
            "  Silhouette Score: 0.6134\n",
            "  Calinski-Harabasz Score: 113914.7769\n",
            "  Davies-Bouldin Score: 0.5192\n",
            "\n",
            "\n",
            "--- Finding Optimal K (A6, A7) ---\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import mean_squared_error, r2_score, silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "\n",
        "def load_and_prepare_data(file_path):\n",
        "    #loading the dataset\n",
        "\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    # slecting the numerical  columns for regression and for clustering\n",
        "    numerical_df = df.select_dtypes(include=[np.number])\n",
        "\n",
        "    return numerical_df\n",
        "\n",
        "\n",
        "\n",
        "def train_simple_linear_regression(X_train_single_feature, y_train_actual):\n",
        "\n",
        "    # as scikit -learn expect 2D array reshaping the data\n",
        "    X_train_reshaped = X_train_single_feature.values.reshape(-1, 1)\n",
        "    reg_model = LinearRegression().fit(X_train_reshaped, y_train_actual)\n",
        "    return reg_model\n",
        "\n",
        "def train_multiple_linear_regression(X_train_multi_feature, y_train_actual):\n",
        "    multi_reg_model = LinearRegression().fit(X_train_multi_feature, y_train_actual)\n",
        "    return multi_reg_model\n",
        "\n",
        "def calculate_regression_metrics(model, X_data, y_true):\n",
        "    # ensuring X_data is a 2D array for prediction\n",
        "    if len(X_data.shape) == 1:\n",
        "        X_data = X_data.values.reshape(-1, 1)\n",
        "\n",
        "    # making predictions\n",
        "    y_pred = model.predict(X_data)\n",
        "\n",
        "    # Calculating metrics\n",
        "    mse = mean_squared_error(y_true, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "\n",
        "    metrics = {\n",
        "        'MSE': mse,\n",
        "        'RMSE': rmse,\n",
        "        'MAPE (%)': mape,\n",
        "        'R2 Score': r2\n",
        "    }\n",
        "    return metrics\n",
        "\n",
        "# A4, A5, A6, A7: Clustering Functions\n",
        "\n",
        "def perform_kmeans_clustering(X_data, k_clusters):\n",
        "\n",
        "    # Setting n_init explicitly to 10 to avoid futurewarning and ensure stability\n",
        "    kmeans = KMeans(n_clusters=k_clusters, random_state=42, n_init=10).fit(X_data)\n",
        "    return kmeans\n",
        "\n",
        "def evaluate_clustering_performance(X_data, labels):\n",
        "  #calculating the silhouetee,calinski-Harabasz and Davies-Bouldin scores\n",
        "    scores = {\n",
        "        'Silhouette Score': silhouette_score(X_data, labels),\n",
        "        'Calinski-Harabasz Score': calinski_harabasz_score(X_data, labels),\n",
        "        'Davies-Bouldin Score': davies_bouldin_score(X_data, labels)\n",
        "    }\n",
        "    return scores\n",
        "\n",
        "def find_optimal_k_and_plot(X_data, max_k=11):\n",
        "  #calculating clustering metrics for k 2 to max_k\n",
        "\n",
        "    distortions = []\n",
        "    silhouette_scores = []\n",
        "    ch_scores = []\n",
        "    db_scores = []\n",
        "    k_values = range(2, max_k)\n",
        "\n",
        "    for k in k_values:\n",
        "        kmeans_model = perform_kmeans_clustering(X_data, k_clusters=k)\n",
        "\n",
        "        # For elbow method (A7)\n",
        "        distortions.append(kmeans_model.inertia_)\n",
        "\n",
        "        # For metric evaluation (A6)\n",
        "        labels = kmeans_model.labels_\n",
        "        silhouette_scores.append(silhouette_score(X_data, labels))\n",
        "        ch_scores.append(calinski_harabasz_score(X_data, labels))\n",
        "        db_scores.append(davies_bouldin_score(X_data, labels))\n",
        "\n",
        "    # Plotting the results\n",
        "    plt.style.use('seaborn-v0_8-whitegrid')\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 11))\n",
        "    fig.suptitle('Finding the Optimal Number of Clusters (k)', fontsize=16)\n",
        "\n",
        "    # 1. Elbow Method Plot\n",
        "    axes[0, 0].plot(k_values, distortions, 'bo-')\n",
        "    axes[0, 0].set_title('A7: Elbow Method (Inertia)')\n",
        "    axes[0, 0].set_xlabel('Number of clusters (k)')\n",
        "    axes[0, 0].set_ylabel('Inertia (Lower is better)')\n",
        "\n",
        "    # 2. Silhouette Score Plot\n",
        "    axes[0, 1].plot(k_values, silhouette_scores, 'go-')\n",
        "    axes[0, 1].set_title('A6: Silhouette Score vs. k')\n",
        "    axes[0, 1].set_xlabel('Number of clusters (k)')\n",
        "    axes[0, 1].set_ylabel('Score (Higher is better)')\n",
        "\n",
        "    # 3. Calinski-Harabasz Score Plot\n",
        "    axes[1, 0].plot(k_values, ch_scores, 'ro-')\n",
        "    axes[1, 0].set_title('A6: Calinski-Harabasz Score vs. k')\n",
        "    axes[1, 0].set_xlabel('Number of clusters (k)')\n",
        "    axes[1, 0].set_ylabel('Score (Higher is better)')\n",
        "\n",
        "    # 4. Davies-Bouldin Score Plot\n",
        "    axes[1, 1].plot(k_values, db_scores, 'mo-')\n",
        "    axes[1, 1].set_title('A6: Davies-Bouldin Score vs. k')\n",
        "    axes[1, 1].set_xlabel('Number of clusters (k)')\n",
        "    axes[1, 1].set_ylabel('Score (Lower is better)')\n",
        "\n",
        "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "    plt.savefig('optimal_k_plots.png')\n",
        "    print(\"Clustering analysis plots saved to 'optimal_k_plots.png'\")\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Data Preparation\n",
        "    file_path = '/content/features_filtered.csv'\n",
        "    numerical_data = load_and_prepare_data(file_path)\n",
        "\n",
        "    #Regression Analysis ---\n",
        "    # Per assignment, for a non-regression problem, we select a numerical\n",
        "    # attribute to act as the target. Here, we choose 'Pz..__alpha'.\n",
        "    y_reg = numerical_data['Pz..__alpha']\n",
        "    X_reg = numerical_data.drop('Pz..__alpha', axis=1)\n",
        "\n",
        "    # Split data for regression models\n",
        "    X_reg_train, X_reg_test, y_reg_train, y_reg_test = train_test_split(\n",
        "        X_reg, y_reg, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    print(\"=\" * 50)\n",
        "    print(\"### A1, A2, A3: Regression Analysis Results ###\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Simple Linear Regression (A1, A2)\n",
        "\n",
        "    X_train_simple = X_reg_train['Cz..__alpha']\n",
        "    X_test_simple = X_reg_test['Cz..__alpha']\n",
        "\n",
        "    simple_model = train_simple_linear_regression(X_train_simple, y_reg_train)\n",
        "\n",
        "    print(\"\\n--- Metrics for SIMPLE feature model (using 'Cz..__alpha') ---\")\n",
        "    train_metrics_simple = calculate_regression_metrics(simple_model, X_train_simple, y_reg_train)\n",
        "    test_metrics_simple = calculate_regression_metrics(simple_model, X_test_simple, y_reg_test)\n",
        "\n",
        "    print(\"Training Set Metrics:\")\n",
        "    for key, value in train_metrics_simple.items():\n",
        "        print(f\"  {key}: {value:.4f}\")\n",
        "\n",
        "    print(\"\\nTest Set Metrics:\")\n",
        "    for key, value in test_metrics_simple.items():\n",
        "        print(f\"  {key}: {value:.4f}\")\n",
        "\n",
        "    # Multiple Linear Regression (A3)\n",
        "    multi_model = train_multiple_linear_regression(X_reg_train, y_reg_train)\n",
        "\n",
        "    print(\"\\n\\n--- Metrics for MULTIPLE feature model (all attributes) ---\")\n",
        "    train_metrics_multi = calculate_regression_metrics(multi_model, X_reg_train, y_reg_train)\n",
        "    test_metrics_multi = calculate_regression_metrics(multi_model, X_reg_test, y_reg_test)\n",
        "\n",
        "    print(\"Training Set Metrics:\")\n",
        "    for key, value in train_metrics_multi.items():\n",
        "        print(f\"  {key}: {value:.4f}\")\n",
        "\n",
        "    print(\"\\nTest Set Metrics:\")\n",
        "    for key, value in test_metrics_multi.items():\n",
        "        print(f\"  {key}: {value:.4f}\")\n",
        "\n",
        "    # clustering analysis ---\n",
        "    print(\"\\n\" + \"=\" * 50)\n",
        "    print(\"### A4, A5, A6, A7: Clustering Analysis Results ###\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # using all numerical data for clustering to find its inherent structure.\n",
        "    X_cluster = numerical_data.copy()\n",
        "\n",
        "    # A4 & A5: K-Means with k=2\n",
        "    k_demo = 2\n",
        "    kmeans_demo = perform_kmeans_clustering(X_cluster, k_clusters=k_demo)\n",
        "\n",
        "    print(f\"\\n--- Clustering Evaluation Metrics for k={k_demo} (A5) ---\")\n",
        "    cluster_scores = evaluate_clustering_performance(X_cluster, kmeans_demo.labels_)\n",
        "    for key, value in cluster_scores.items():\n",
        "        print(f\"  {key}: {value:.4f}\")\n",
        "\n",
        "    # A6 & A7\n",
        "    print(\"\\n\\n--- Finding Optimal K (A6, A7) ---\")\n",
        "    find_optimal_k_and_plot(X_cluster)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s_k4fO9cnxz0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rtrgv7u69vH-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}